<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>《数据密集型应用系统设计》-第二章读书笔记</title>
    <link href="/2020/07/23/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E7%AC%AC%E4%BA%8C%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/07/23/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E7%AC%AC%E4%BA%8C%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<p>《数据密集型应用系统设计》第二章的标题是数据模型与查询语言。大部分应用都是通过一层一层叠加数据模型进行应用构建，复杂的应用可能会有很多的中间层，但核心思想都是通过提供一个简洁的数据模型来隐藏下层的复杂性。本章介绍一系列用于数据存储和查询的通用数据模型，讨论多重查询语言并比较它们的使用场景。</p><h1 id="关系模型与文档模型"><a href="#关系模型与文档模型" class="headerlink" title="关系模型与文档模型"></a>关系模型与文档模型</h1><p>目前最著名的数据模型可能是SQL，它是基于关系模型：数据呗组织成关系（relations），在SQL中称为表（table），其中每个关系都是元组（tuples）的无序集合（行）。关系模型的目标就是将实现细节隐藏在更简洁的接口后面。</p><p>除了关系模式，业界也出现了很多竞争技术，如对象数据库、xml数据库等，但都无一持久。进入21世纪后，NoSQL成为了一个新的竞争者，NoSQL有着很多自身独有的优势。目前看来后续一段时间内，关系数据库很可能继续与各种非关系数据存储一起使用。</p><blockquote><p>NoSQL的特性：</p><ul><li>比关系数据库更好的扩展性，支持大数据集或更高的吞吐量</li><li>免费开源而不是商业</li><li>关系型无法很好支持的特定操作</li><li>更具动态和表达力的数据模型</li></ul></blockquote><h2 id="对象-关系不匹配"><a href="#对象-关系不匹配" class="headerlink" title="对象-关系不匹配"></a>对象-关系不匹配</h2><p>数据储存在关系表中，应用层代码中的对象与表、行和列的数据库模型之间需要一个笨拙的转换层。像一些场景（如简历等）的数据，用JSON表示会比较合适，查询和维护时，只需要操作一个地方即可。这个是文档型数据的优势。</p><h2 id="多对一与多对多的关系"><a href="#多对一与多对多的关系" class="headerlink" title="多对一与多对多的关系"></a>多对一与多对多的关系</h2><p>在一些场景中，对关系的引用比较敏感，如以下场景。为了减少重复冗余数据，保证数据的一致性，这正是数据库规范化的核心思想。</p><ul><li>输入项需符合规范</li><li>避免歧义（字面相同，但含义不同的数据）</li><li>易于更新</li><li>本地化支持</li><li>更好的搜索支持</li></ul><p>像这种需要表达多对一的关系，并不是很适合文档模型。如果数据库本身不支持联结，则需要在应用程序的代码中实现，导致代码的复杂型增加。</p><h2 id="文档数据库发展的历史借鉴"><a href="#文档数据库发展的历史借鉴" class="headerlink" title="文档数据库发展的历史借鉴"></a>文档数据库发展的历史借鉴</h2><p>为了解决数据表达的局限性，历史上提出了关系模型和网络模型，两个模式也经历了很多争论。</p><h3 id="网络模型"><a href="#网络模型" class="headerlink" title="网络模型"></a>网络模型</h3><p>网络模型由一个称为数据系统语言会议的委员会进行标准化，被称为CODASYL模型。在该模型中，一个记录可以有多个父节点，记录直接的连接不是外键，而更像是编程语言中的指针。访问记录的方法是选择一条始于根记录的路径，并沿着相关的链接依次访问。访问路径更像是遍历链表：从链表的头部开始，一次查看一个记录，知道找到所需的记录。<br>该模型能够有效的利用硬件资源，但最大的问题是查询和更新数据库异常复杂而没有灵活性，需要大量的手写数据库查询代码。</p><h3 id="关系模型"><a href="#关系模型" class="headerlink" title="关系模型"></a>关系模型</h3><p>关系模型定义了所有数据的格式，没有复杂的嵌套结构，也没有复杂的访问路径。可以读取表中的任何一行或者所有行，支持任意条件的查询。同时也可以根据某些列作为键匹配特定行的数据。<br>在关系数据库中，查询优化器自动决定以何种顺序执行查询，以及使用哪些索引。这些相当于网络模型的路径，但这些无需开发者关注，而是通过查询优化器自动进行处理。</p><h3 id="文档模型"><a href="#文档模型" class="headerlink" title="文档模型"></a>文档模型</h3><p>文档模型在表达多对一和多对多的关系时，与关系数据库没有本质不同，都只能通过唯一的标识符引用。</p><h2 id="关系数据库与文档数据库现状"><a href="#关系数据库与文档数据库现状" class="headerlink" title="关系数据库与文档数据库现状"></a>关系数据库与文档数据库现状</h2><p>文档数据库模型主要优点是模式灵活，由于局部性而带来较好的性能。同时对于应用来说，它的数据结构也更加接近应用程序。关系模型则是强在联结操作、多对一、多对多关系更简洁的表达上。</p><h3 id="哪种数据模型的应用代码更简单"><a href="#哪种数据模型的应用代码更简单" class="headerlink" title="哪种数据模型的应用代码更简单"></a>哪种数据模型的应用代码更简单</h3><p>应用数据具有类似文档的结构，使用文档模型更为合适，如果使用了多对多关系，那么文档模型很有可能导致应用程序代码更复杂、性能更差。应用代码的复杂性取决于数据项之前的关系类型，对于高度关联的数据，文档模型不太适合，关系模型可以胜任，而图模型最为自然。</p><h3 id="文档模型中的模式灵活性"><a href="#文档模型中的模式灵活性" class="headerlink" title="文档模型中的模式灵活性"></a>文档模型中的模式灵活性</h3><p>文档数据库存进行数据存储时，一般不会对数据内容进行校验，因此在数据读取是，应用需要自己保证读取数据的完整性。这种差异还提现在数据的结构改变时，关系数据库需要对存量的数据进行数据修复。</p><h3 id="查询的数据局部性"><a href="#查询的数据局部性" class="headerlink" title="查询的数据局部性"></a>查询的数据局部性</h3><p>同一文档通常存储在连续区域，需要进行频繁访问时，可以快速返回整个文档。如果数据存在多个表中，则需要多次检索，消耗更多的IO时间。</p><h3 id="文档数据库与关系数据库的融合"><a href="#文档数据库与关系数据库的融合" class="headerlink" title="文档数据库与关系数据库的融合"></a>文档数据库与关系数据库的融合</h3><p>随时时间推移，关系型数据库正在对文档的一些特性进行支持，即能处理文档类数据，还能对其执行行关系查询。</p><h1 id="数据查询语言"><a href="#数据查询语言" class="headerlink" title="数据查询语言"></a>数据查询语言</h1><p>命令式语言告诉计算机以特定顺序执行某些操作。你完全可以推理整个过程，逐行遍历代码、评估相关条件、更新对应的变量，并决定是否执行。<br>声明式语言，则只需指定所需的数据模式，结果需满足什么条件，以及如何转换数据，而不需要致命如何实现这一目标。数据库系统的查询优化器会决定采用哪些索引和联结，以及用如何顺序来执行查询的各个语句。对外隐藏了数据库引擎的很多实现细节。</p><h2 id="Web上的声明式查询"><a href="#Web上的声明式查询" class="headerlink" title="Web上的声明式查询"></a>Web上的声明式查询</h2><p>对于Web浏览器的例子，使用声明式CSS样式比用Javascript命令式操作样式容易的多。类似地，在数据库中，像SQL这样的声明式查询语言比命令式查询APIs要好得多。</p><h2 id="MapReduce查询"><a href="#MapReduce查询" class="headerlink" title="MapReduce查询"></a>MapReduce查询</h2><p>MapReduce既不是声明式查询语言，也不是一个完全命令式的查询API，而是介于两者之前：查询的逻辑用代码片段来说表示，这些代码片段可以被处理框架重复地调用。</p><p>MapReduce是一个相当底层的变成模型，用于在计算机群众分布执行。而SQL这样的更高层次的查询语言可以通过一些MapReduce操作pipeline来实现。</p><h1 id="图状数据模型"><a href="#图状数据模型" class="headerlink" title="图状数据模型"></a>图状数据模型</h1><p>多对多关系用图表示比较合适，图由两种对象组成：顶点（也称为结点或实体）和边（也称为关系或弧）。很多数据可以建模为图。</p><p>有多重不同但相关的方法可以构建和查询图中的数据。属性图模型（property graph）和三元存储模型（triple-store）</p><p>示例。<br><img src="/2020/07/23/《数据密集型应用系统设计》-第二章读书笔记/IMG54.jpeg" srcset="/img/loading.gif" alt=""></p><h2 id="属性图"><a href="#属性图" class="headerlink" title="属性图"></a>属性图</h2><p>在属性图模型中，每个顶点包括：</p><ul><li>唯一的标识符</li><li>出边的集合</li><li>入边的集合</li><li>属性的集合（键-值对）</li></ul><p>每个边包括：</p><ul><li>唯一的标识符</li><li>边开始的顶点（尾部顶点）</li><li>边结束的顶点（头部顶点）</li><li>描述两个顶点间关系类型的标签</li><li>属性的集合（键-值对）</li></ul><p>可以将图存储看做由两个关系表组成，一个用于顶点，另一个用于边。关于图模型一些值得注意的地方：</p><ol><li>任何顶点都可以连接到其他任何顶点。没有模式限制哪种事物可以或不可以关联。</li><li>给定某个顶点，可以高效地得到它的所有入边和出边，从而遍历图。</li><li>通过对不同类型的关系使用不同的标签，可以在单个图中存储多重不同类型的信息，同时仍然保持整洁的数据模型。</li></ol><p>用关系模式来表示属性图<br><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> vertices (vertex_id <span class="hljs-built_in">integer</span> PRIMARY <span class="hljs-keyword">KEY</span>,properties <span class="hljs-keyword">json</span>);<span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> edges (edge_id <span class="hljs-built_in">integer</span> PRIMARY <span class="hljs-keyword">KEY</span>,tail_vertex <span class="hljs-built_in">integer</span> <span class="hljs-keyword">REFERENCES</span> vertices(vertex_id),head_vertex <span class="hljs-built_in">integer</span> <span class="hljs-keyword">REFERENCES</span> vertices(vertex_id),label <span class="hljs-built_in">text</span>,properties <span class="hljs-keyword">json</span>)<span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">INDEX</span> edges_tails <span class="hljs-keyword">ON</span> edges(tail_vertex);<span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">INDEX</span> edges_heads <span class="hljs-keyword">ON</span> edges(head_vertex);</code></pre></p><h2 id="Cypher查询语言"><a href="#Cypher查询语言" class="headerlink" title="Cypher查询语言"></a>Cypher查询语言</h2><p>Cypher是一种用于属性图的声明式查询语言，最早为Neo4j图形数据库而创建。</p><p>对应上述示例，采用Cypher方式进行数据插入：<br><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> (NAmerica:Location &#123;<span class="hljs-keyword">name</span>:<span class="hljs-string">'North America'</span>, <span class="hljs-keyword">type</span>:<span class="hljs-string">'continent'</span>&#125;),(USA:Location &#123;<span class="hljs-keyword">name</span>:<span class="hljs-string">'United States'</span>, <span class="hljs-keyword">type</span>:<span class="hljs-string">'country'</span>&#125;),(Idaho:Location &#123;<span class="hljs-keyword">name</span>:<span class="hljs-string">'Idaho'</span>, <span class="hljs-keyword">type</span>:<span class="hljs-string">'state'</span>&#125;),(Lucy:Person &#123;<span class="hljs-keyword">name</span>:<span class="hljs-string">'Idaho'</span>, <span class="hljs-keyword">type</span>:<span class="hljs-string">'state'</span>&#125;),(Idaho) -[:<span class="hljs-keyword">WITHIN</span>]-&gt; (USA) -[:<span class="hljs-keyword">WITHIN</span>]-&gt; (NAmerica),(Lucy) -[:BORN_IN]-&gt; (Idaho)</code></pre></p><p>采用Cypher查询从美国移民到欧洲的人员名单:<br><pre><code class="hljs sql">MATCH(person) -[:BORN_IN]-&gt; () -[:WITHIN*o..]-&gt; (us:Location &#123;name:'United States'&#125;),(person) -[:LIVES_IN]-&gt; () -[:WITHIN*o..]-&gt; (en:Location &#123;name:'Europe'&#125;)RETURN person.name</code></pre></p><h2 id="SQL中的图查询"><a href="#SQL中的图查询" class="headerlink" title="SQL中的图查询"></a>SQL中的图查询</h2><p>在关系型数据库中，通常会预先知道查询中需要哪些join操作。而对于图查询，在找到要查找的顶点之前，可能需要遍历数量未知的边。也就是说，join操作数量并不是预先确定的。在SQL中可以采用递归公用表达式来执行与上述示例相同的查询。</p><h2 id="三元存储与SPARQL"><a href="#三元存储与SPARQL" class="headerlink" title="三元存储与SPARQL"></a>三元存储与SPARQL</h2><p>三元存储模式几乎与属性图模型相同，在三元存储中，所有信息都以三部分形式存储（主体，谓语，客体）。三元组的主体相当于图中的顶点，而客体存在以下两种情况：1. 三元组的谓语与客体分别相当于主题（顶点）属性中的键和值；2. 谓语是图中的边，主体是尾部顶点，而客体是头部顶点。</p><p>使用三元组表示上述示例：<br><pre><code class="hljs sql">@prefix : &lt;urn:example:&gt;._:lucy a :Person; name "Lucy"; :bornIn _:idaho._:idaho a :Location; :name "Idaho"; type "state"; :within _:usa._:usa a :Location; :name "United States"; :type "country"; :within _:namerica.:namerica a :Location; :name "NOrth America"; :type "continent".</code></pre></p><p>后面的RDF数据模型和SPARQL都是一些比较细节具体的信息，在这就不展开叙述了。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>在本章主要是介绍了一些不同的数据模型，每种数据模型都有自己的适用范围，同时每个数据模型也都有自己的查询语言和框架。</p>]]></content>
    
    
    <categories>
      
      <category>读书笔记</category>
      
      <category>数据密集型应用系统设计</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据</tag>
      
      <tag>架构</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《数据密集型应用系统设计》-第一章读书笔记</title>
    <link href="/2020/07/22/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/07/22/%E3%80%8A%E6%95%B0%E6%8D%AE%E5%AF%86%E9%9B%86%E5%9E%8B%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E3%80%8B-%E7%AC%AC%E4%B8%80%E7%AB%A0%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<p>《数据密集型应用系统设计》第一章主要介绍了数据处理系统架构设计上的三个目标：可靠性、可扩展性、可维护性。</p><h1 id="可靠性（Reliability）"><a href="#可靠性（Reliability）" class="headerlink" title="可靠性（Reliability）"></a>可靠性（Reliability）</h1><p>当出现意外情况如硬件、软件故障、人为失误等，系统应可以继续正常运转。虽然性能可能有所下降，但确保功能正常。</p><p>可能出错的事情称为错误（faults）或故障，系统可应对错误则称为容错（fault-tolerant）或者弹性（resilient）。系统可以容忍各种可能的故障类型是不可能的，因此容错是指特定类型的故障。<br>故障与失效（failure）不完全一致。故障通常被定义为组件偏离其正常规格，而失效意味系统作为一个整体停止，无法向用户提供所需的服务。通常设计容错机制来避免从故障引发系统失效。</p><ul><li>硬件故障</li><li>软件错误</li><li>人为失误</li></ul><h1 id="可扩展性（Scalability）"><a href="#可扩展性（Scalability）" class="headerlink" title="可扩展性（Scalability）"></a>可扩展性（Scalability）</h1><p>随着规模的增长，例如数据量、流量或复杂性，系统应以合理的方式来匹配这种增长。</p><p>即使系统现在工作可靠，并不意味着它将来一定能够可靠运转。发生退化的一个常见原因是负载增加了。</p><ol><li>首先我们需要简洁的描述系统当前的负载，负载可以用称为负载参数的若干数字来描述，参数的最佳选择取决于系统的体系结构。</li><li>描述负载之后，我们关注性能指标。通常关心吞吐量（throughput），即每秒可处理的记录条数，或者在某指定数据集上运行作业所需的总时间；而在线系统通常更看重服务的响应时间（response time），即客户端从发送请求到接受响应之间的间隔。如果想知道更典型的响应时间，平均值并不是合适的指标，最好使用百分位数（percentiles）。</li></ol><blockquote><p>延迟与响应时间。延迟（latency）和响应时间（response time）容易混淆使用，但它们并不完全一样。通常响应时间是客户端看到的：除了处理请求时间（服务时间、service time）外，还包括来回网络延迟和各种排队延迟。延迟则是请求花费在处理上的时间。</p></blockquote><ol start="3"><li>应对负载增加的方法<ul><li>针对特定级别负载而设计架构，需要认真考虑目标服务的负载增长情况。</li><li>可以通过垂直扩展（升级硬件）和水平扩展（增加实例数量）应对负载增加，但最终往往无法避免水平扩展。同时可以考虑使用弹性方式自动检测负载增加，自动添加计算资源。</li><li>扩展能力往往基于某些假设，在项目初期，应该快速迭代推出产品功能，比应对不可知的扩展性更重要。</li></ul></li></ol><h1 id="可维护性（Maintainability）"><a href="#可维护性（Maintainability）" class="headerlink" title="可维护性（Maintainability）"></a>可维护性（Maintainability）</h1><p>随着时间的推移，许多新的人员参与到系统开发和运维，以维护现有功能或适配新场景等，系统都应高效运转。</p><p>软件的大部分成本并不在最初的开发阶段，而是在于整个生命周期内持续的投入，这包括维护与缺陷修复，监控系统来保持正常运行、故障排查、适配新平台、搭配新场景、技术缺陷的完善以及增加新功能等。</p><ol><li>一些操作应该是自动化的，使得运维更加轻松。同时使得日常工作变得更简单，让团队能够专注于高附加值的任务。</li><li>降低系统复杂性可以提高软件的可维护性。通过抽象消除复杂性，隐藏实现细节，对外提供干净简单的接口。</li><li>架构设计的目标还应该考虑轻松的修改系统，让其适应不断变化的需求。</li></ol>]]></content>
    
    
    <categories>
      
      <category>读书笔记</category>
      
      <category>数据密集型应用系统设计</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据</tag>
      
      <tag>架构</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《Flink基础教程》--读书笔记1</title>
    <link href="/2018/12/05/%E3%80%8AFlink%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/"/>
    <url>/2018/12/05/%E3%80%8AFlink%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/</url>
    
    <content type="html"><![CDATA[<p>流处理的优势：</p><ol><li>能够以非常低的延迟处理数据</li><li>较低的成本能带来较好的容错性</li></ol><p>流式技术的发展<br><img src="/2018/12/05/《Flink基础教程》-读书笔记1/006tNbRwgy1fxw3ydcisfj311o0u0wq4.jpg" srcset="/img/loading.gif" alt=""></p><a id="more"></a><p>Flink架构<br><img src="/2018/12/05/《Flink基础教程》-读书笔记1/006tNbRwgy1fxw40pqbjyj313o0q8ae9.jpg" srcset="/img/loading.gif" alt=""></p><p>Flink的分布式特点体现在它能够在成百上千台机器上运行，它将大型的计算任务分成许多小的部分，每个机器执行一个部分。Flink 能够自动地确保在发生机器故障或者其他错误时计算能持续进行，或者在修复bug或进行版本升级后有计划地再执行一次。这种能力使得开发人员不需要担心失败。Flink本质上使用容错性数据流，这使得开发人员可以分析持续生成且永远不结束的数据(即流处理)。</p><p>Flink常用的架构：</p><ol><li>数据传输层<br>1） 高性能及持久化：作为数据缓冲区，将短时间的数据保留，持久化的特性使得消息可以重播。<br>2） 将生产者和消费者进行解耦： 可以支持从多个源收集数据，并把数据提供给多个服务使用。</li><li>流处理层</li></ol><p>事件时间 是事件创建的时间。它通常由事件中的时间戳描述，例如附接在生产传感器，或者生产服务。Flink通过时间戳分配器访问事件时间戳。<br>摄入时间 是事件进入Flink数据流源算符的时间。<br>处理事件 是每一个执行时间操作的算符的本地时间。</p><p><img src="/2018/12/05/《Flink基础教程》-读书笔记1/006tNbRwgy1fyb8xxrnlpj310s0h2whf.jpg" srcset="/img/loading.gif" alt=""></p><p>窗口</p><ol><li><p>时间窗口，有滚动窗口和滑动窗口，滚动按结束时间，滑动按开始时间。</p><pre><code class="hljs java">stream.timeWindow(Time.minutes(<span class="hljs-number">1</span>), Time.seconds(<span class="hljs-number">30</span>))</code></pre></li><li><p>计数窗口，</p><pre><code class="hljs java">stream.countWindow(<span class="hljs-number">4</span>, <span class="hljs-number">2</span>)</code></pre></li><li><p>会话窗口，用户与网站进行一系列 交互(活动阶段)之后，关闭浏览器或者不再交互(非活动阶段)</p><pre><code class="hljs java">stream.window(SessionWindows.withGap(Time.minutes(<span class="hljs-number">5</span>))</code></pre></li></ol><p><img src="/2018/12/05/《Flink基础教程》-读书笔记1/006tNbRwgy1fyb8zk6y9ej30ya06ujs4.jpg" srcset="/img/loading.gif" alt=""></p><p>水印<br>表示当前不会再有比水印时间早的流水，具体见如下链接：<br><a href="https://blog.csdn.net/a6822342/article/details/78064815" target="_blank" rel="noopener">https://blog.csdn.net/a6822342/article/details/78064815</a></p><p>状态<br>流式计算分为无状态和有状态两种情况。无状态的计算观察每个独立事件，并根据最后一个事件输出结果。有状态的计算则会基于多个事件输出结果。</p><p>一致性</p><ul><li>at-most-once:这其实是没有正确性保障的委婉说法——故障发生之后，计数结果可能丢失。</li><li>at-least-once:这表示计数结果可能大于正确值，但绝不会小于正确值。也就是说，计数程序在发生故障后可能多算，但是绝不会少算。</li><li>exactly-once:这指的是系统保证在发生故障后得到的计数结果与正确值一致。</li></ul><p>容错检查点</p><p>Flink使用 流重放 与 Checkpoint 的结合实现了容错。Checkpoint与每一个输入流及其相关的每一个算符的状态的特定点相关联。一个流数据流可以可以从一个checkpoint恢复出来，其中通过恢复算符状态并从检查点重放事件以保持一致性（一次处理语义）<br>检查点间隔是以恢复时间（需要重放的事件数量）来消除执行过程中容错的开销的一种手段。</p><p>Flink基础教程比较薄，对介绍的特性也是点到即止。</p>]]></content>
    
    
    <categories>
      
      <category>读书笔记</category>
      
      <category>Flink基础教程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>Flink</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论软件可靠性设计技术的应用</title>
    <link href="/2018/11/09/%E8%AE%BA%E8%BD%AF%E4%BB%B6%E5%8F%AF%E9%9D%A0%E6%80%A7%E8%AE%BE%E8%AE%A1%E6%8A%80%E6%9C%AF%E7%9A%84%E5%BA%94%E7%94%A8/"/>
    <url>/2018/11/09/%E8%AE%BA%E8%BD%AF%E4%BB%B6%E5%8F%AF%E9%9D%A0%E6%80%A7%E8%AE%BE%E8%AE%A1%E6%8A%80%E6%9C%AF%E7%9A%84%E5%BA%94%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<p>【摘要】<br>2017年4月份，某股份制银行启动了新征信管理平台的系统项目，本人所在的大数据支持处室负责了数据存储、查询及数据标准化等功能的建设，本人作为项目经办负责技术方案的管理和设计。征信管理平台是我行风险控制的重要部分，维护有个人、对公征信、互联网小贷、电信运营商等数据。征信管理平台承载了大量业务在风险控制环节对数据的诉求，如新发卡、贷前、贷中等关键业务流程，因此行内提出了较高的可靠性要求。为达到该系统的可靠性要求，本人带领合作公司团队对系统的运行环境和特点等进行分析，根据分析出的结果制定了提高系统可靠性的措施：一是采用了健康检查的思路，出现故障后可自动拉起应用并告警；二是降低主流程复杂度，将主流程外的处理通过队列异步处理。三是容错机制的设计，建议业务采购多家供应商的接口，形成主备模式。至从2017年6月开放第一批接口，截至2017年年末已接入数据源40余个，系统投产后大量的外部征信数据能在有效期内得到复用，节约了大量的费用，同时系统的高性能、高可用性的特点也得到业务部门的一致好评。<br><a id="more"></a><br>【正文】<br>随着银行业的快速发展，各业务部门对风险管理的要求越来越高，需要更加丰富的征信数据帮忙完成业务流程，同时旧征信平台中使用的传统应用和数据库架构已无法满足业务发展的需求，因此行内提出了建设新征信管理平台的诉求。大量的征信外部数据也是对大数据平台数据源的一个完善，因此我所在的处室承担了相关数据存储、查询及数据标准化等功能的建设（本文中仅对实时应用部分讨论，离线部分不具体展开），本人负责技术方案的管理和设计。总体上系统采用了微服务的架构：1、查询服务按业务领域进行划分，有征信服务、运营商服务、个人属性服务等负责具体数据的查询、主备供应商的切换及数据的标准化，并且将查询后的数据及相关的日志信息防止队列中间件中；2、数据回写服务负责从队列将数据入库，并根据规则生成有效期等字段，以便数据复用。3、服务治理的相关组件，注册中心负责管理服务的元信息；配置中心负责管理各服务的配置文件；网关负责交易请求的路由。4、数据存储上采用了分布式的中间件Elasticsearch，过程中直接存取非结构化数据，减少关联查询。</p><p>征信管理平台涉及的关键业务流程多，访问量大，因此行内提出了较高的可靠性要求。要提高系统的可靠性指标，团队首先进行可靠性影响分析，主要采用了故障树分析方法。故障树分析方法是一种自顶向下的软件可靠性分析方法，从软件系统不希望发生的事件向下逐步追查导致事件发生的原因，直至基本事件，从而确定软件故障的原因。经过分析，我们找出了以下导致故障发生的基本事件：</p><p>一、运行硬件，应用所依赖的运行硬件并不是完全可靠的，随着时间推移，硬件会发生老化从而产生故障。</p><p>二、模块规模及内部结构的复杂度，模块的规模越大、复杂度越高，其开发测试的难度也越大，我们需要尽量降低主流程的复杂度，让整个架构实现更加可控。</p><p>三、外部依赖，征信数据的来源是第三方的数据服务提供商，每个服务提供商的服务质量参差不齐。虽然有商务合同进行约束，但实际情况中经常会出现无法提供服务的情况。</p><p>常用的软件可靠性技术有容错设计、检错设计、降低复杂度设计等。容错设计可以通过冗余或者备份的方式代替故障服务，从而维护软件系统的正常运行；检错设计是当软件系统出现故障时能及时发现并告警提示维护人员处理的能力；降低复杂度设计的思想是保证实现软件功能的基础上，简化软件结构，优化软件数据流向，降低软件复杂度，从而提高软件可靠性。根据以上的分析，结合行内的技术特点，我们制定了如下的可靠性设计方案。</p><p>一、在整体的部署架构中采用多活的方式进行部署，建立健康检查的机制，并且与行内集中告警平台对接。</p><p>应用服务以多实例的方式部署在行内已有docker云平台中，应用暴露接口供云平台进行健康检查，若长时间判断为不健康时，云平台可自动拉起新的服务实例，关闭故障实例，并进行统一告警。同时在应用逻辑中提供了重试的请求机制，通过网关服务进行流量分发时，若无法分发至目标服务，则会重试分发逻辑。如仍无法分发，则会从注册中心中挑选另一个可用实例进行分发路由，保障服务的连续。</p><p>二、降低业务主流程程序中的复杂度，将回写数据、日志信息等放入到kafka消息队列中间件中，后续由其他应用进行数据消费处理。</p><p>征信数据在业务定义的有效期内可反复使用，节约外发请求第三方的费用，因此需要将查询后的数据结果进行存储。在该方案设计中，查询后的数据会直接放入到消息队列中，由数据回写服务根据业务配置的有效期规则，计算数据有效期后进行入库。该设计将查询和写入操作解耦，模块之间消除依赖，查询服务外的应用出现故障，最坏结果只是会造成服务降级，无法查得存量数据，并不会影响正常的业务的开展。由于各服务的轻量级设计思路，后续的维护复杂度降低，便于评估变更影响，提高整个系统的可靠性。</p><p>三、采用了冗余设计的思路，向业务建议采购多个提供相同服务的数据提供商形成服务的主备架构。</p><p>第三方的服务质量及数据质量都无法控制，从设计上规划了两种策略进行冗余，1）主备供应商，即查询时根据业务配置的主供应商进行查询，业务可按需进行切换；2）优先级策略，即优先查询高优先级的供应商，若无法得到满足业务的服务（如第三方服务无响应或关键字段为空），则继续查询下一优先级的服务，保证业务不受第三方影响。这个设计思路也得到了业务的高度认可，在某次快速发卡（现场申请虚拟信用卡进行消费）的业务场景中，第三方接口突然服务中断，业务按指引进行了供应商优先级的切换，快速的解决了问题，保证了业务不受影响。</p><p>该项目架构稳定后，本人于17年年底交接了该系统的相关事项，截至当时，已接入数据源40余个，每日的查询量已接近千万级。在项目组各位的努力下，该系统也得到了各部门的一致好评。通过本次的项目架构实践，我学习了提高可靠性相关的分析方法和设计思路，也深刻体会到了系统架构设计和选择对项目影响的重要性。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>论软件系统架构评估</title>
    <link href="/2018/11/09/%E8%AE%BA%E8%BD%AF%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AF%84%E4%BC%B0/"/>
    <url>/2018/11/09/%E8%AE%BA%E8%BD%AF%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AF%84%E4%BC%B0/</url>
    
    <content type="html"><![CDATA[<p>2017年4月份，某股份制银行启动了新征信管理平台的系统项目，本人所在的大数据支持处室负责了数据存储、查询及数据标准化等功能的建设，本人作为项目经办负责技术方案的管理和设计。征信管理平台是我行风险控制的重要部分，维护有个人、对公征信、互联网小贷、电信运营商等数据。征信管理平台承载了大量业务在风险控制环节对数据的诉求，如新发卡、贷前、贷中等关键业务流程。<br>本文论述了软件系统的架构评估，首先分析了软件架构评估所普遍关注的质量属性并阐述了其性能、可用性、可修改性和安全性的具体含义。整个系统采用了微服务的架构设计方法。在架构设计完成之后，对SA评估采用了基于场景的评估方式中的体系结构权衡分析方法ATAM，并详细描述了其评估过程，项目评估小组经过对项目的风险点、敏感点和权衡点的讨论后生成了质量效应树。目前系统已稳定运行一年多，从而验证了该项目采用ATAM架构评估保证了系统的顺利完成。</p><a id="more"></a><p>随着银行业的快速发展，各业务部对风险管理的要求越来越高，需要更加丰富的征信数据帮忙完成业务流程，同时旧征信平台中使用的传统应用和数据库架构已无法满足业务发展的需求，因此行内提出了建设新征信管理平台的诉求。大量的征信外部数据也是对大数据平台数据源的一个完善，因此我所在的处室承担了相关数据存储、查询及数据标准化等功能的建设（本文中仅对实时应用部分讨论，离线部分不具体展开），本人负责技术方案的管理和设计。</p><p>总体上系统采用了微服务的架构：1、查询服务按业务领域进行划分，有征信服务、运营商服务、个人属性服务等负责具体数据的查询、主备供应商的切换及数据的标准化，并且将查询后的数据及相关的日志信息防止队列中间件中；2、数据回写服务负责从队列将数据入库，并根据规则生成有效期等字段，以便数据复用。3、服务治理的相关组件，注册中心负责管理服务的元信息；配置中心负责管理各服务的配置文件；网关负责交易请求的路由。4、数据存储上采用了分布式的中间件Elasticsearch，过程中直接存取非结构化数据，减少关联查询。征信管理平台涉及的关键业务流程多，访问量大，因此行内提出了较多的质量属性要求，下面先介绍下软件架构评估的质量属性。</p><p>架构评估是软件开发过程中的重要环节，在软件架构评估中的质量属性有：性能、可用性、可修改性、安全性、可测试性、可靠性和易用性等。其中前4个质量属性是质量效应树的重要组成部分。性能是指系统的响应能力，即经过多长时间对事件做出响应。可用性是指系统能够正常运行的比例，通过用两次故障之间的时间长度或出现故障时系统能够恢复的速度来表示。可修改性是指系统能以较高的性价比对系统做出变更的能力。安全性是指系统能够向合法用户提供服务，同时拒绝非授权用户使用或拒绝服务的能力。<br>常用的架构评估方法有：基于问卷调查的评估方式、基于场景的评估方式和基于度量的评估方式。基于问卷调查的评估方式是由多个评估专家通过调查问卷的方式回答问卷中的问题，对多个评估结果进行综合，最终得到最终结果。其评价的具有主观性不太适合本项目。基于度量的评估方式虽然评价比较客观，但是需要评估者对系统的架构有精确的了解，也不太适合本项目。而基于场景的评估要求评估者对系统中等了解，评价比较主观，故本项目采用了基于场景的评估方式。基于场景的评估方式又分为架构权衡分析法ATAM，软件架构分析法SAAM和成本效益分析法CBAM。本项目中根据不同质量属性使用了ATAM作为系统架构评估的方法。</p><p>在使用ATAM进行架构评估时，我们根据项目需要成立了项目评估小组。其主要成员包括：评估小组负责人、项目决策者、架构设计师、用户、开发人员、测试人员、系统部署人员等项目干系人。架构的评估经历了描述和介绍阶段、调查和分析阶段、测试阶段和报告阶段四个阶段。下面我分别从这四个阶段进行介绍。</p><p>在描述和介绍阶段，由于项目评估成员有部分人员对ATAM并不熟悉，因此项目组首先学习了ATAM的方法。它是一种基于场景的软件架构评估方法，对系统的多个质量属性基于场景进行评估。通过该评估确认系统存在的风险，并检查各自的非功能性需求是否满足需求。业务重点阐述了系统的目的和举例说明了使用的场景，我也和大家介绍了本次项目中采用的微服务架构，并解析了各模块的功能。</p><p>在调查分析阶段，业务部门提出了性能及高可用的要求，因为大量的业务场景需要使用到这些数据，并且部分场景对时间非常敏感。另外开发人员提出为了当不断增加数据供应商时，需要快速的进行接入，保证系统的开发效率及系统修改性，可以进行并行开发。</p><p>针对这些场景我们分析了项目开发过程中的风险点、敏感点和权衡点。经过分析，该项目中存在以下风险点：当第三方供应商无法提供服务时，会直接影响业务可用性；敏感点有：用户的加密级别、漏洞规则的修改。权衡点有：为提高可用性，需增加主备模式，当主供应商失效时，能切换至选供应商继续提供服务，但因为主备供应商的报文格式、数据字典都有差异，需要进行标准化，势必影响系统的可修改性。</p><p>在测试阶段：经过评估小组集体讨论，确定了不同场景的优先级如下：系统的可用性最高，性能其次，可修改性较低。在保证系统可用性方面，在流量捕获部分使用双机热备技术，在两个捕获系统之间设置心跳，当一台捕获系统出问题，另一台捕获设备接管。在流量自动化分析部分，采用了集群部署技术，一台分析设备出问题，不会影响整个分析系统。在保证数据安全性方面，磁盘采用企业磁盘阵列raid5机制。在用户数据安全性方面，采用了非对称加密及信息摘要技术。</p><p>最后形成了评估报告，经过对架构的评估，确定了系统的风险点、敏感点、权衡点和非风险点，最后以文档的形式表现。其包括的内容包括：架构分析方法文档、架构的不同场景及各自的优先级、质量效应树、风险点决策、非风险点决策及每次的评估会议记录。</p><p>该项目开发工作于2016年8月完工，系统上线后，我们的安全分析人员和客户使用该系统对互联网流量进行漏洞挖掘，一共产生了150种以上的web流量攻击流量特征和5个未知web漏洞。在国家某安全中心网研室的其他项目中起到了支撑作用，尤其是某变量覆盖漏洞、某文件写入漏洞，某sql注入漏洞在项目使用过程中取得了一定得效果，得到了好评。为开展互联网安全事件得防御、发现、预警和协调处置等工作提供了数据依据，更好的维护了国家公共互联网安全，保障基础信息网络和重要信息系统的安全运行。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>论软件架构的选择</title>
    <link href="/2018/11/09/%E8%AE%BA%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84%E7%9A%84%E9%80%89%E6%8B%A9/"/>
    <url>/2018/11/09/%E8%AE%BA%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84%E7%9A%84%E9%80%89%E6%8B%A9/</url>
    
    <content type="html"><![CDATA[<p>论文摘要</p><p>2017年4月份，某股份制银行启动了新征信管理平台的系统项目，本人所在的大数据支持处室负责了数据存储、查询及数据标准化等功能的建设，本人作为项目经办负责技术方案的管理和设计。征信管理平台是我行风险控制的重要部分，维护有个人、对公征信、互联网小贷、电信运营商等数据。征信管理平台承载了大量业务在风险控制环节对数据的诉求，如新发卡、贷前、贷中等关键业务流程。本文介绍了几种主要架构风格及特点，论述了该项目在软件架构选择过程中，为何选择了三种风格的组合。最后，文章总结了采用该组合风格后带来的好处及缺点。</p><a id="more"></a><p>论文正文</p><p>背景介绍</p><p>随着银行业的快速发展，各业务部对风险管理的要求越来越高，需要更加丰富的征信数据帮忙完成业务流程，同时旧征信平台中使用的传统应用和数据库架构已无法满足业务发展的需求，因此行内提出了建设新征信管理平台的诉求。大量的征信外部数据也是对大数据平台数据源的一个完善，因此我所在的处室承担了相关数据存储、查询及数据标准化等功能的建设（本文中仅对实时应用部分讨论，离线部分不具体展开），本人负责技术方案的管理和设计。</p><p>主要架构风格介绍</p><p>在基本需求确认后，我们开始了系统架构的选择，首先是对常用的架构风格进行了分析。管道/过滤器风格，每个构件都有一组输入和输出，构件读输入的数据流，经过内部处理，然后产生输出数据流。这里的构件被称为过滤器，这种风格的连接件就像是数据流传输的管道，将一个过滤器的输出传到另一过滤器的输入。<br>基于事件的隐式调用风格，其思想是构件不直接调用一个过程，而是触发或广播一个或多个事件。系统中的其它构件中的过程在一个或多个事件中注册，当一个事件被触发，系统自动调用在这个事件中注册的所有过程，这样，一个事件的触发就导致了另一模块中的过程的调用。<br>微服务风格，是指开发一个单个小型的但有业务功能的服务，每个服务都有自己的处理和轻量通讯机制，可以部署在单个或多个服务器上。微服务也指一种种松耦合的、有一定的有界上下文的面向服务架构。<br>三层分层架构，将整个业务应用划分为界面层、业务逻辑层、数据访问层，目的是为了“高内聚低耦合”的思想。</p><p>架构风格选择</p><p>结合业务需求和行内现有技术框架及系统环境的实际情况，最终我们再整体上选择了微服务架构，部分模块中使用分层架构，事件驱动，数据库系统这三种风格的混合模式。</p><p>在系统整体架构选择上，主要考虑了系统的可用性、性能及可扩展性，采用了微服务的风格：1、查询服务按业务领域进行划分，有征信服务、运营商服务、个人属性服务等负责具体数据的查询、主备供应商的切换及数据的标准化，并且将查询后的数据及相关的日志信息防止队列中间件中；2、数据回写服务负责从队列将数据入库，并根据规则生成有效期等字段，以便数据复用。3、服务治理的相关组件，注册中心负责管理服务的元信息；配置中心负责管理各服务的配置文件；网关负责交易请求的路由。4、业务数据存储上采用了分布式的中间件Elasticsearch，过程中直接存取非结构化数据，减少关联查询。按业务领域划分查询服务可以使得扩展更加灵活，不同业务领域的修改不会互相影响，当后续不同领域的数据供应商新增时，只需要新增服务，不需要修改远服务减少影响范围。同时个别繁忙服务需要扩充资源时，也能灵活扩充，不会造成浪费。</p><p>在面向业务使用的后台管理服务中，首先我们为了安装方便，采用了B/S架构，整体上将系统分为页面表现层，业务逻辑层及数据持久层这三层。表现层采用jsp文件实现，业务逻辑层为一组java service，数据持久层采用mybatis xml文件实现。这样设计的原因是可以降低层与层之间的依赖，便于各层逻辑的复用，在后期维护的时候，极大地降低了维护成本和维护时间</p><p>实际业务需求调研时我们了解到用户在多个地方有审批需求，比如业务机会阶段变更到2阶段时，项目名称修改时，及项目非正常关闭时，考虑到可能还会有其他地方需要审批，而审批是一个比较独立的功能模块，有自己的一系列行为，审批功能可能也会随着外部比如OA系统升级而做修改或替换。所以这里我们采用了事件驱动架构，将审批功能分装成一个独立构件，将启动审批流程过程注册到审批事件中，各个需要的功能界面只需触发审批事件即可。</p><p>总结</p><p>项目耗时4个月时间最终成功上线，上线后得到使用单位用户和领导的高度认可，至今使用已经超过两年，后期维护过程中，用户单位由于业务分工及组织架构调整，项目池要求由原先的按照行业来划分修改为按照地区来划分，由于我们将项目池分类定义在数据库系统中，所以我们很快地就满足了用户的修改需求。另外，我们发现到采用该混合架构也存在一些缺陷，比如B/S分层架构带来的页面查询性能不佳，随着数据量的增加，首页刷新时间一度增加到8秒以上，针对这个问题，我们后来将首页分成几个块用多线程的方式分别独立刷新，现在速度提高至3秒左右。</p><p>通过这个项目，本人更进一步了解到系统架构设计的重要性，也意识到各类架构风格只为满足核心业务场景系统需求的本质。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>《Kafka技术内幕》--读书笔记5</title>
    <link href="/2018/09/12/%E3%80%8AKafka%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B05/"/>
    <url>/2018/09/12/%E3%80%8AKafka%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B05/</url>
    
    <content type="html"><![CDATA[<p>消费者的配置信息要指定连接的ZK集群以及消费组编号。消费者客户端会通过消费者连接器(ConsumerConnector)连接ZK集群，获取分配的分区，创建每个主题对应的消息流(KafkaStream),最后迭代消息流，读取每条消息，并完成具体的业务处理逻辑(这里只是简单地打印出收到的每条信息)。</p><p>消费者客户端通过消费者连接器读取消息的具体步骤如下。</p><ol><li>消费者的配置信息指定订阅的主题和主题对应的线程数，每个线程对应一个消息流。</li><li>Consumer对象通过配置文件创建基于ZK的消费者连接器。</li><li>消费者连接器根据主题和线程数创建多个消息流。</li><li>在每个消息流通过循环消费者迭代器(ConsumerIterator)读出消息。</li></ol><p><img src="/2018/09/12/《Kafka技术内幕》-读书笔记5/006tNbRwgy1fve31c9uixj315w0hmap1.jpg" srcset="/img/loading.gif" alt=""></p><a id="more"></a><h1 id="创建并初始化消费者连接器"><a href="#创建并初始化消费者连接器" class="headerlink" title="创建并初始化消费者连接器"></a>创建并初始化消费者连接器</h1><p>默认的消费者连接器实现类是ZookeeperConsumerConnector，消费者连接器还会协调下面的各个组件来读取消息。</p><ul><li>listeners。注册主题分区的更新、会话超时、消费者成员变化事件，触发再平衡。</li><li>zkUtils。从ZK中获取主题、分区、消费者列表，为再平衡时的分区分配提供决策。</li><li>topicRegistry。消费者分配的分区，结构是“主题→(分区→分区信息)”。</li><li>fetcher。消费者拉取线程的管理类，拉取线程会向服务端拉取分区的消息。</li><li>topicThreadldAndQueues。消费者订阅的主题和线程数，每个线程对应一个队列。</li><li>offsetsChannel。偏移量存储为Kafka内部主题时，需要和管理消费组的协调者通信。</li></ul><p>监听器(1)是消息消费事件的导火索，一旦触发了再平衡，需要从ZK中读取所有的分区和已注册的消费者(2)。然后通过分区分配算法，每个消费者都会分配到不同的分区列表(3)。接着拉取线程开始拉取对应的分区消息(4)，并将拉取到的消息放到每个线程的队列中(5)，最后消费者客户端就可以从队列中读取出消息了。另外，为了及时保存消费进度，我们还需要将偏移量保存至offsetsChannel通道对应的节点中(6)。</p><p><img src="/2018/09/12/《Kafka技术内幕》-读书笔记5/006tNbRwgy1fve3a31wmpj312q0q2nl9.jpg" srcset="/img/loading.gif" alt=""></p><h1 id="消费者客户端的线程模型"><a href="#消费者客户端的线程模型" class="headerlink" title="消费者客户端的线程模型"></a>消费者客户端的线程模型</h1><p>消费者连接器的createMessageStreams()方法会调用consume()方法，但consume()方法并不真正消费数据，而只是为消费消息做准备工作。</p><ol><li>根据客户端传入的topicCountMap构造对应的队列和消息流，消息流引用了队列。</li><li>在ZK的消费组父节点下注册消费者子节点。</li><li>执行初始化工作，触发再平衡，为消费者分配分区，拉取线程会拉取消息放到队列中。</li><li>返回消息流列表，队列中有数据时，客户端就可以从消息流中迭代读取消息。</li></ol><p>消费者客户端线程模型的主要概念有消费者线程、队列、消息流，这三者的关系都是一一对应的。如果将线程模型和服务端的分区再结合起来，一个线程允许分配多个分区，那么多个分区会共用同一个线程对应的一个队列和一个消息流。下面我们分析几个和消费者线程模型相关的变量。</p><ul><li>topicCountMap，设置主题及其对应的线程个数，每个钱程都对应一个队列和一个消息流。</li><li>consumer时，即“消费者编号”，用“消费组名称+随机值”表示，指定消费者在消费组中的唯一编号。</li><li>ConsumerThreadid，即“消费者线程编号”，用“消费者编号+线程编号”表示。</li><li>consumerThreadidsPerTopicMap，表示每个主题和消费者线程编号集合的映射关系。</li><li>topicThreadids，表示所有的消费者线程编号集合，相同主题的线程会在同一个数组里。</li><li>topicThreadidAndQueues，表示消费者线程和队列的映射关系，因为每个线程对应一个队列。</li></ul><p>消费者客户端只需要指主订阅的主题和线程数量，具体主题分成几个分区、线程分配到了哪些分区、分区分布在哪些节点上，对客户端都是透明的。客户端的关注点是每个线程都对应一个队列，每个队列都对应了一个消息流，只要队列中有数据，就能从消息流中迭代读取出消息。</p><p>队列作为消息流和拉取线程的共享内存数据结构，会通过消费者连接器的topicThreadldAndQueues全局引用，传递到拉取线程。当拉取线程往队列中填充数据时，消费者客户端就可以通过消息流从队列读取消息。</p><p><img src="/2018/09/12/《Kafka技术内幕》-读书笔记5/006tNbRwgy1fve4139m62j310u0am107.jpg" srcset="/img/loading.gif" alt=""></p><h1 id="重新初始化消费者"><a href="#重新初始化消费者" class="headerlink" title="重新初始化消费者"></a>重新初始化消费者</h1><p>消费者连接器的consume()方法在注册消费者至ZK后，调用reinitializeConsumer()方法执行重新初始化。消费者启动时希望被加入消费组，必须执行一次初始化方法，并触发消费组内所有消费者成员(当然也包括自己)的再平衡。</p><p>每个消费者在启动时都要订阅3种事件:会话超时事件、消费组的子节点变化事件(消费者增减)、主题的数据变化事件(分区增减)。这3种事件任何一个发生，都会触发再平衡操作。如果从消费组级别来看，其他消费者也会订阅这些事件，也都会发生再平衡。即消费组中的所有消费者都会发生再平衡。</p>]]></content>
    
    
    <categories>
      
      <category>读书笔记</category>
      
      <category>Kafka技术内幕</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>kafka</tag>
      
      <tag>Kafka技术内幕</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《Kafka技术内幕》--读书笔记4</title>
    <link href="/2018/09/08/%E3%80%8AKafka%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B04/"/>
    <url>/2018/09/08/%E3%80%8AKafka%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B04/</url>
    
    <content type="html"><![CDATA[<p>Kafka集群的数据需要被不同类型的消费者使用，而不同类型的消费者处理逻辑不同。Kafka使用消费组的概念，允许一组消费者进程对消费工作进行划分。每个消费者都可以配置一个所属的消费组，并且订阅多个主题。Kafka会发送每条消息给每个消费组中的一个消费者迫二程(同一条消息广播给多个消费组，单播给同一组中的消费者)。被订阅主题的所有分区会平均地负载给订阅方，即消费组中的所有消费者。</p><p>Kafka采用消费组保证了“一个分区只可被消费组中的一个消费者所消费”，这意味着:</p><ol><li>在一个消费组中，一个消费者可以消费多个分区。</li><li>不同的消费者消费的分区一定不会重复，所有消费者一起消费所有的分区。</li><li>在不同消费组中，每个消费组都会悄费所有的分区。</li><li>同一个消费组下消费者对分区是互斥的，而不同消费组之间是共享的。</li></ol><a id="more"></a><p>Kafka实现传统队列的方式:</p><ul><li>发布-订阅模式。同一条消息会被多个消费组消费，每个消费组只有一个消费者，实现广播。</li><li>队列模式。只有一个消费组、多个消费者一条消息只被消费组的一个消费者消费，实现单播。</li></ul><p><img src="/2018/09/08/《Kafka技术内幕》-读书笔记4/006tNbRwgy1fv293227ecj316m0imtqg.jpg" srcset="/img/loading.gif" alt=""></p><p>一旦出现消费组内消费者的调整，消费组内的消费者需要执行再平衡的工作。再平衡操作针对的是消费组中的所有消费者，所有消费者都妥执行重新分配分区的动作。再平衡前的消费者保存了分区的消费进度，再平衡后的消费者就可以从保存的进度位置继续读取分区。</p><p><img src="/2018/09/08/《Kafka技术内幕》-读书笔记4/006tNbRwgy1fv29bbgmv5j314m0jmtq1.jpg" srcset="/img/loading.gif" alt=""></p><p>生产者的提交日志采用递增的偏移量，连同消息内容一起写入本地日志文件。生产者客户端不需要保存偏移量相关的状态，消费者客户端则要保存消费消息的偏移盘即消费进度。消费进度表示消费者对一个分区已经消费到了哪里。</p><p>消费者对分区的消费进度通常保存在外部存储系统中，比如ZK或者Kafka的内部主题(consume_offsets)。</p><p><img src="/2018/09/08/《Kafka技术内幕》-读书笔记4/006tNbRwgy1fv2aefbamzj31820bu498.jpg" srcset="/img/loading.gif" alt=""></p><p>一个分区只能属于一个消费者线程，将分区分配给消费者有以下几种场景。</p><ol><li>线程数量多于分区的数量，有部分钱程无法消费该主题下任何一条消息。</li><li>线程数量少于分区的数量，有一些线程会消费多个分区的数据。</li><li>线程数量等于分区的数量，则正好一个钱程消费一个分区的数据。</li></ol><p><img src="/2018/09/08/《Kafka技术内幕》-读书笔记4/006tNbRwgy1fv2ais7607j31aq0bydqy.jpg" srcset="/img/loading.gif" alt=""></p><p>一个消费者线程消费多个分区，可以保证消费同一个分区的消息一定是有序的，但并不保证消费者接收到多个分区的消息完全有序。</p><p>消费者除了需要保存消费进度到ZK中，它分配的分区也是从ZK读取的。ZK不仅存储了Kafka的内部元数据，而且记录了消费组的成员列表、分区的消费进度、分区的所有者。表3-1总结了消息代理节点、主题、分区、消费者、偏移量(offset)、所有权(ownership)在ZK中的注册信息。</p><p><img src="/2018/09/08/《Kafka技术内幕》-读书笔记4/006tNbRwgy1fv60qzxur8j31dw10ckjl.jpg" srcset="/img/loading.gif" alt=""></p><ul><li>高级API。消费者客户端代码不需要管理偏移量的提交，并且采用了消费组的向动负载均衡功能，确保消费者的增减不会影响消息的消费。高级API提供了从Kafka消费数据的高层抽象。</li><li>低级API。通常针对特殊的消费逻辑，比如消费者只想消费某些特定的分区。低级API的客户端代码需要自己实现一些和Kafka服务端相关的底层逻辑，比如选择分区的主剧本、处理主副本的故障转移等也</li></ul>]]></content>
    
    
    <categories>
      
      <category>读书笔记</category>
      
      <category>Kafka技术内幕</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>kafka</tag>
      
      <tag>Kafka技术内幕</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《Kafka技术内幕》--读书笔记3</title>
    <link href="/2018/08/13/%E3%80%8AKafka%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B03/"/>
    <url>/2018/08/13/%E3%80%8AKafka%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B03/</url>
    
    <content type="html"><![CDATA[<h1 id="客户端消息发送线程"><a href="#客户端消息发送线程" class="headerlink" title="客户端消息发送线程"></a>客户端消息发送线程</h1><p>我们先按照分区的主副本节点进行分组，把属于同一个节点的所有分区放在一起，合并成一个请求发送。</p><p><img src="/2018/08/13/《Kafka技术内幕》-读书笔记3/0069RVTdgy1fu8gxn3kihj30uq0j2n9f.jpg" srcset="/img/loading.gif" alt=""></p><a id="more"></a><ol><li>消息被记录收集器收集，并按照分区追加到队列的最后一个批记录中。</li><li>发送钱程通过ready()从记录收集器中找出已经准备好的服务端节点。</li><li>节点已经准备好，如果客户端还没有和它们建立连接，通过connect()建立到服务端的连接。</li><li>发送线程通过drain()从记录收集器获取按照节点整理好的每个分区的批记录。</li><li>发送线程得到每个节点的批记录后，为每个节点创建客户端请求，并将请求发送到服务端。</li></ol><p><img src="/2018/08/13/《Kafka技术内幕》-读书笔记3/0069RVTdgy1fu8i82lx23j31de0luwzc.jpg" srcset="/img/loading.gif" alt=""></p><h1 id="创建生产者客户端请求"><a href="#创建生产者客户端请求" class="headerlink" title="创建生产者客户端请求"></a>创建生产者客户端请求</h1><p>发送线程并不负责真正发送客户端请求，它会从记录收集器中取出要发送的消息，创建好客户端请求，然后把请求交给客户端网络对象(NetworkClient)去发送。因为没有在发送线程中发送请求，所以创建客户端请求时需要保留目标节点，这样客户端网络对象获取出客户端请求时，才能知道要发送给哪个目标节点。</p><h2 id="准备发送客户端请求"><a href="#准备发送客户端请求" class="headerlink" title="准备发送客户端请求"></a>准备发送客户端请求</h2><p>客户端向服务端发送请求需要先建立网络连接。如果服务端还没有准备好，即还不能连接，这个节点在客户端就会被移除掉，确保消息不会发送给还没有准备好的节点;如果服务端已经准备好了，则调用selector.connect()方法建立到目标节点的网络连接。 </p><pre><code class="hljs java"><span class="hljs-comment">/** * Begin connecting to the given node, return true if we are already connected and ready to send to that node. * * <span class="hljs-doctag">@param</span> node The node to check * <span class="hljs-doctag">@param</span> now The current timestamp * <span class="hljs-doctag">@return</span> True if we are ready to send to the given node */</span><span class="hljs-meta">@Override</span><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">ready</span><span class="hljs-params">(Node node, <span class="hljs-keyword">long</span> now)</span> </span>&#123;    <span class="hljs-keyword">if</span> (node.isEmpty())        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> IllegalArgumentException(<span class="hljs-string">"Cannot connect to empty node "</span> + node);    <span class="hljs-keyword">if</span> (isReady(node, now))        <span class="hljs-keyword">return</span> <span class="hljs-keyword">true</span>;    <span class="hljs-keyword">if</span> (connectionStates.canConnect(node.idString(), now))        <span class="hljs-comment">// if we are interested in sending to a node and we don't have a connection to it, initiate one</span>        initiateConnect(node, now);    <span class="hljs-keyword">return</span> <span class="hljs-keyword">false</span>;&#125;</code></pre><p>这一步只是将请求暂存到节点对应的网络通道中，还没有真正地将客户端请求发送出去。</p><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title">doSend</span><span class="hljs-params">(ClientRequest clientRequest, <span class="hljs-keyword">boolean</span> isInternalRequest, <span class="hljs-keyword">long</span> now)</span> </span>&#123;    String nodeId = clientRequest.destination();    <span class="hljs-keyword">if</span> (!isInternalRequest) &#123;        <span class="hljs-comment">// If this request came from outside the NetworkClient, validate</span>        <span class="hljs-comment">// that we can send data.  If the request is internal, we trust</span>        <span class="hljs-comment">// that that internal code has done this validation.  Validation</span>        <span class="hljs-comment">// will be slightly different for some internal requests (for</span>        <span class="hljs-comment">// example, ApiVersionsRequests can be sent prior to being in</span>        <span class="hljs-comment">// READY state.)</span>        <span class="hljs-keyword">if</span> (!canSendRequest(nodeId))            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> IllegalStateException(<span class="hljs-string">"Attempt to send a request to node "</span> + nodeId + <span class="hljs-string">" which is not ready."</span>);    &#125;    AbstractRequest request = <span class="hljs-keyword">null</span>;    AbstractRequest.Builder&lt;?&gt; builder = clientRequest.requestBuilder();    <span class="hljs-keyword">try</span> &#123;        NodeApiVersions versionInfo = nodeApiVersions.get(nodeId);        <span class="hljs-comment">// Note: if versionInfo is null, we have no server version information. This would be</span>        <span class="hljs-comment">// the case when sending the initial ApiVersionRequest which fetches the version</span>        <span class="hljs-comment">// information itself.  It is also the case when discoverBrokerVersions is set to false.</span>        <span class="hljs-keyword">if</span> (versionInfo == <span class="hljs-keyword">null</span>) &#123;            <span class="hljs-keyword">if</span> (discoverBrokerVersions &amp;&amp; log.isTraceEnabled())                log.trace(<span class="hljs-string">"No version information found when sending message of type &#123;&#125; to node &#123;&#125;. "</span> +                        <span class="hljs-string">"Assuming version &#123;&#125;."</span>, clientRequest.apiKey(), nodeId, builder.version());        &#125; <span class="hljs-keyword">else</span> &#123;            <span class="hljs-keyword">short</span> version = versionInfo.usableVersion(clientRequest.apiKey());            builder.setVersion(version);        &#125;        <span class="hljs-comment">// The call to build may also throw UnsupportedVersionException, if there are essential</span>        <span class="hljs-comment">// fields that cannot be represented in the chosen version.</span>        request = builder.build();    &#125; <span class="hljs-keyword">catch</span> (UnsupportedVersionException e) &#123;        <span class="hljs-comment">// If the version is not supported, skip sending the request over the wire.</span>        <span class="hljs-comment">// Instead, simply add it to the local queue of aborted requests.</span>        log.debug(<span class="hljs-string">"Version mismatch when attempting to send &#123;&#125; to &#123;&#125;"</span>,                clientRequest.toString(), clientRequest.destination(), e);        ClientResponse clientResponse = <span class="hljs-keyword">new</span> ClientResponse(clientRequest.makeHeader(),                clientRequest.callback(), clientRequest.destination(), now, now,                <span class="hljs-keyword">false</span>, e, <span class="hljs-keyword">null</span>);        abortedSends.add(clientResponse);        <span class="hljs-keyword">return</span>;    &#125;    RequestHeader header = clientRequest.makeHeader();    <span class="hljs-keyword">if</span> (log.isDebugEnabled()) &#123;        <span class="hljs-keyword">int</span> latestClientVersion = ProtoUtils.latestVersion(clientRequest.apiKey().id);        <span class="hljs-keyword">if</span> (header.apiVersion() == latestClientVersion) &#123;            log.trace(<span class="hljs-string">"Sending &#123;&#125; to node &#123;&#125;."</span>, request, nodeId);        &#125; <span class="hljs-keyword">else</span> &#123;            log.debug(<span class="hljs-string">"Using older server API v&#123;&#125; to send &#123;&#125; to node &#123;&#125;."</span>,                header.apiVersion(), request, nodeId);        &#125;    &#125;    Send send = request.toSend(nodeId, header);    InFlightRequest inFlightRequest = <span class="hljs-keyword">new</span> InFlightRequest(            header,            clientRequest.createdTimeMs(),            clientRequest.destination(),            clientRequest.callback(),            clientRequest.expectResponse(),            isInternalRequest,            send,            now);    <span class="hljs-keyword">this</span>.inFlightRequests.add(inFlightRequest);    selector.send(inFlightRequest.send);&#125;</code></pre><p>针对同一个服务端，如果上一个客户端请求还没有发送完成，则不允许发送新的客户端请求。客户端网络连接对象用inFlightRequsts变量在客户端缓存了还没有收到响应的客户端请求，InFlightRequests类包含一个节点到双端队列的映射结构。在准备发送客户端请求时，请求将添加到指定节点对应的队列中;在收到响应后，才会将请求从队列中移除。</p><h2 id="客户端轮询并调用回调函数"><a href="#客户端轮询并调用回调函数" class="headerlink" title="客户端轮询并调用回调函数"></a>客户端轮询并调用回调函数</h2><p>发送线程run()方法的最后一步是调用NetworkClient的poll()方法。轮询的最关键步骤是调用selector.poll()方法，而在轮询之后，定义了多个处理方法。轮询不仅仅会发送客户端请求，也会接收客户端响应。客户端发送请求后会调用handleCompletedSends()处理已经完成的发送，客户端接收到响应后会调用handleCompletedReceives()处理已经完成的接收。<br>如果客户端发送完请求不需要响应，在处理已经完成的发送时，就会将对应的请求从iFlightRequests队列中移踪。而因为没有响应结果，也就不会有机会调用handleCompletedReceives()方法。如果客户端请求需要响应，则只有在handleCompletedReceives()中才会删除对应的请求:因为inFlightRequests队列保存的是未收到响应的客户端请求，请求已经有响应，就不需要存在于队列中。</p><pre><code class="hljs java"><span class="hljs-comment">/** * Do actual reads and writes to sockets. * * <span class="hljs-doctag">@param</span> timeout The maximum amount of time to wait (in ms) for responses if there are none immediately, *                must be non-negative. The actual timeout will be the minimum of timeout, request timeout and *                metadata timeout * <span class="hljs-doctag">@param</span> now The current time in milliseconds * <span class="hljs-doctag">@return</span> The list of responses received */</span><span class="hljs-meta">@Override</span><span class="hljs-function"><span class="hljs-keyword">public</span> List&lt;ClientResponse&gt; <span class="hljs-title">poll</span><span class="hljs-params">(<span class="hljs-keyword">long</span> timeout, <span class="hljs-keyword">long</span> now)</span> </span>&#123;    <span class="hljs-keyword">long</span> metadataTimeout = metadataUpdater.maybeUpdate(now);    <span class="hljs-keyword">try</span> &#123;        <span class="hljs-keyword">this</span>.selector.poll(Utils.min(timeout, metadataTimeout, requestTimeoutMs));    &#125; <span class="hljs-keyword">catch</span> (IOException e) &#123;        log.error(<span class="hljs-string">"Unexpected error during I/O"</span>, e);    &#125;    <span class="hljs-comment">// process completed actions</span>    <span class="hljs-keyword">long</span> updatedNow = <span class="hljs-keyword">this</span>.time.milliseconds();    List&lt;ClientResponse&gt; responses = <span class="hljs-keyword">new</span> ArrayList&lt;&gt;();    handleAbortedSends(responses);    handleCompletedSends(responses, updatedNow);    handleCompletedReceives(responses, updatedNow);    handleDisconnections(responses, updatedNow);    handleConnections();    handleInitiateApiVersionRequests(updatedNow);    handleTimedOutRequests(responses, updatedNow);    <span class="hljs-comment">// invoke callbacks</span>    <span class="hljs-comment">// 上面几个处理都会往responses中添加数据，有了响应后开始调用请求的回调函数</span>    <span class="hljs-keyword">for</span> (ClientResponse response : responses) &#123;        <span class="hljs-keyword">try</span> &#123;            response.onComplete();        &#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;            log.error(<span class="hljs-string">"Uncaught error in request completion:"</span>, e);        &#125;    &#125;    <span class="hljs-keyword">return</span> responses;&#125;</code></pre><ol><li>不需要响应的流程。开始发送请求→添加客户端请求到队列→发送请求→请求发送成功→从队列中删除发送请求→构造客户端响应。</li><li>需要晌应的流程。开始发送请求→添加客户端请求到队列→发送请求→请求发送成功→等待接收响应→接收响应→接收到完整的响应→从队列中删除客户端请求→构造客户端响应。</li></ol>]]></content>
    
    
    <categories>
      
      <category>读书笔记</category>
      
      <category>Kafka技术内幕</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>kafka</tag>
      
      <tag>Kafka技术内幕</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《Kafka技术内幕》--读书笔记2</title>
    <link href="/2018/07/18/%E3%80%8AKafka%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/"/>
    <url>/2018/07/18/%E3%80%8AKafka%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B02/</url>
    
    <content type="html"><![CDATA[<p>Kafka初期使用Scala编写，早期Scala版本的生产者、消费者和服务端的实现都放在core包下;而最新的客户端使用了Java重新实现，放在clients包下。</p><h1 id="新生产者"><a href="#新生产者" class="headerlink" title="新生产者"></a>新生产者</h1><p>新的生产者应用程序使用KafkaProducer对象代表一个生产者客户端进程。生产者要发送消息，并不是直接发送给服务端，而是先在客户端把消息放入队列中，然后由一个消息发送线程从队列中拉取消息，以批量的方式发送消息给服务端。Kafka的记录收集器(RecordAccumulator)负责缓存生产者客户端产生的消息，发送线程(Sender)负责读取记录收集器的批量消息，通过网络发送给服务端。为了保证客户端网络请求的快速响应，Kafka使用选择器(Selector)处理网络连接和读写处理，使用网络连接(NetworkClient)处理客户端网络请求。</p><a id="more"></a><h2 id="发送消息"><a href="#发送消息" class="headerlink" title="发送消息"></a>发送消息</h2><p>Kafka源码根目录的examples包<br><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Producer</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Thread</span> </span>&#123;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> KafkaProducer&lt;Integer, String&gt; producer;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> String topic;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> Boolean isAsync;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">Producer</span><span class="hljs-params">(String topic, Boolean isAsync)</span> </span>&#123;        Properties props = <span class="hljs-keyword">new</span> Properties();        props.put(<span class="hljs-string">"bootstrap.servers"</span>, KafkaProperties.KAFKA_SERVER_URL + <span class="hljs-string">":"</span> + KafkaProperties.KAFKA_SERVER_PORT);        props.put(<span class="hljs-string">"client.id"</span>, <span class="hljs-string">"DemoProducer"</span>);        props.put(<span class="hljs-string">"key.serializer"</span>, <span class="hljs-string">"org.apache.kafka.common.serialization.IntegerSerializer"</span>);        props.put(<span class="hljs-string">"value.serializer"</span>, <span class="hljs-string">"org.apache.kafka.common.serialization.StringSerializer"</span>);        producer = <span class="hljs-keyword">new</span> KafkaProducer&lt;&gt;(props);        <span class="hljs-keyword">this</span>.topic = topic;        <span class="hljs-keyword">this</span>.isAsync = isAsync;    &#125;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">run</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">int</span> messageNo = <span class="hljs-number">1</span>;        <span class="hljs-keyword">while</span> (<span class="hljs-keyword">true</span>) &#123;            String messageStr = <span class="hljs-string">"Message_"</span> + messageNo;            <span class="hljs-keyword">long</span> startTime = System.currentTimeMillis();            <span class="hljs-keyword">if</span> (isAsync) &#123; <span class="hljs-comment">// Send asynchronously</span>                producer.send(<span class="hljs-keyword">new</span> ProducerRecord&lt;&gt;(topic,                    messageNo,                    messageStr), <span class="hljs-keyword">new</span> DemoCallBack(startTime, messageNo, messageStr));            &#125; <span class="hljs-keyword">else</span> &#123; <span class="hljs-comment">// Send synchronously</span>                <span class="hljs-keyword">try</span> &#123;                    producer.send(<span class="hljs-keyword">new</span> ProducerRecord&lt;&gt;(topic,                        messageNo,                        messageStr)).get();                    System.out.println(<span class="hljs-string">"Sent message: ("</span> + messageNo + <span class="hljs-string">", "</span> + messageStr + <span class="hljs-string">")"</span>);                &#125; <span class="hljs-keyword">catch</span> (InterruptedException | ExecutionException e) &#123;                    e.printStackTrace();                &#125;            &#125;            ++messageNo;        &#125;    &#125;&#125;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DemoCallBack</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Callback</span> </span>&#123;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">long</span> startTime;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">int</span> key;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> String message;    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">DemoCallBack</span><span class="hljs-params">(<span class="hljs-keyword">long</span> startTime, <span class="hljs-keyword">int</span> key, String message)</span> </span>&#123;        <span class="hljs-keyword">this</span>.startTime = startTime;        <span class="hljs-keyword">this</span>.key = key;        <span class="hljs-keyword">this</span>.message = message;    &#125;    <span class="hljs-comment">/**     * A callback method the user can implement to provide asynchronous handling of request completion. This method will     * be called when the record sent to the server has been acknowledged. Exactly one of the arguments will be     * non-null.     *     * <span class="hljs-doctag">@param</span> metadata  The metadata for the record that was sent (i.e. the partition and offset). Null if an error     *                  occurred.     * <span class="hljs-doctag">@param</span> exception The exception thrown during processing of this record. Null if no error occurred.     */</span>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">onCompletion</span><span class="hljs-params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;        <span class="hljs-keyword">long</span> elapsedTime = System.currentTimeMillis() - startTime;        <span class="hljs-keyword">if</span> (metadata != <span class="hljs-keyword">null</span>) &#123;            System.out.println(                <span class="hljs-string">"message("</span> + key + <span class="hljs-string">", "</span> + message + <span class="hljs-string">") sent to partition("</span> + metadata.partition() +                    <span class="hljs-string">"), "</span> +                    <span class="hljs-string">"offset("</span> + metadata.offset() + <span class="hljs-string">") in "</span> + elapsedTime + <span class="hljs-string">" ms"</span>);        &#125; <span class="hljs-keyword">else</span> &#123;            exception.printStackTrace();        &#125;    &#125;&#125;</code></pre></p><p>KafkaProducer用send方法，完成同步和l异步两种模式的消息发迭。因为send方法返回的是一个Future。基于Future，我们可以实现同步或异步的消息发送语义。</p><ul><li>同步。调用send返回Future时，需要立即调用get，因为Future.get在没有返回结果时会一直阻塞。</li><li>异步。提供一个回调，调用send后可以继续发送消息而不用等待。当有结果运回时，会向动执行回调函数。</li></ul><p>发送消息实现：<br><pre><code class="hljs java"><span class="hljs-comment">/** * Implementation of asynchronously send a record to a topic. */</span><span class="hljs-function"><span class="hljs-keyword">private</span> Future&lt;RecordMetadata&gt; <span class="hljs-title">doSend</span><span class="hljs-params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>&#123;    TopicPartition tp = <span class="hljs-keyword">null</span>;    <span class="hljs-keyword">try</span> &#123;        <span class="hljs-comment">// first make sure the metadata for the topic is available</span>        <span class="hljs-comment">// 更新对应topic的元数据</span>        ClusterAndWaitTime clusterAndWaitTime = waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs);        <span class="hljs-keyword">long</span> remainingWaitMs = Math.max(<span class="hljs-number">0</span>, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);        Cluster cluster = clusterAndWaitTime.cluster;        <span class="hljs-keyword">byte</span>[] serializedKey;        <span class="hljs-keyword">try</span> &#123;            serializedKey = keySerializer.serialize(record.topic(), record.key());        &#125; <span class="hljs-keyword">catch</span> (ClassCastException cce) &#123;            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> SerializationException(<span class="hljs-string">"Can't convert key of class "</span> + record.key().getClass().getName() +                    <span class="hljs-string">" to class "</span> + producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() +                    <span class="hljs-string">" specified in key.serializer"</span>);        &#125;        <span class="hljs-keyword">byte</span>[] serializedValue;        <span class="hljs-keyword">try</span> &#123;            serializedValue = valueSerializer.serialize(record.topic(), record.value());        &#125; <span class="hljs-keyword">catch</span> (ClassCastException cce) &#123;            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> SerializationException(<span class="hljs-string">"Can't convert value of class "</span> + record.value().getClass().getName() +                    <span class="hljs-string">" to class "</span> + producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() +                    <span class="hljs-string">" specified in value.serializer"</span>);        &#125;        <span class="hljs-keyword">int</span> partition = partition(record, serializedKey, serializedValue, cluster);        <span class="hljs-keyword">int</span> serializedSize = Records.LOG_OVERHEAD + Record.recordSize(serializedKey, serializedValue);        ensureValidRecordSize(serializedSize);        tp = <span class="hljs-keyword">new</span> TopicPartition(record.topic(), partition);        <span class="hljs-keyword">long</span> timestamp = record.timestamp() == <span class="hljs-keyword">null</span> ? time.milliseconds() : record.timestamp();        log.trace(<span class="hljs-string">"Sending record &#123;&#125; with callback &#123;&#125; to topic &#123;&#125; partition &#123;&#125;"</span>, record, callback, record.topic(), partition);        <span class="hljs-comment">// producer callback will make sure to call both 'callback' and interceptor callback</span>        Callback interceptCallback = <span class="hljs-keyword">this</span>.interceptors == <span class="hljs-keyword">null</span> ? callback : <span class="hljs-keyword">new</span> InterceptorCallback&lt;&gt;(callback, <span class="hljs-keyword">this</span>.interceptors, tp);        RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, interceptCallback, remainingWaitMs);        <span class="hljs-keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;            log.trace(<span class="hljs-string">"Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch"</span>, record.topic(), partition);            <span class="hljs-keyword">this</span>.sender.wakeup();        &#125;        <span class="hljs-keyword">return</span> result.future;        <span class="hljs-comment">// handling exceptions and record the errors;</span>        <span class="hljs-comment">// for API exceptions return them in the future,</span>        <span class="hljs-comment">// for other exceptions throw directly</span>    &#125; <span class="hljs-keyword">catch</span> (ApiException e) &#123;        log.debug(<span class="hljs-string">"Exception occurred during message send:"</span>, e);        <span class="hljs-keyword">if</span> (callback != <span class="hljs-keyword">null</span>)            callback.onCompletion(<span class="hljs-keyword">null</span>, e);        <span class="hljs-keyword">this</span>.errors.record();        <span class="hljs-keyword">if</span> (<span class="hljs-keyword">this</span>.interceptors != <span class="hljs-keyword">null</span>)            <span class="hljs-keyword">this</span>.interceptors.onSendError(record, tp, e);        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> FutureFailure(e);    &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;        <span class="hljs-keyword">this</span>.errors.record();        <span class="hljs-keyword">if</span> (<span class="hljs-keyword">this</span>.interceptors != <span class="hljs-keyword">null</span>)            <span class="hljs-keyword">this</span>.interceptors.onSendError(record, tp, e);        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> InterruptException(e);    &#125; <span class="hljs-keyword">catch</span> (BufferExhaustedException e) &#123;        <span class="hljs-keyword">this</span>.errors.record();        <span class="hljs-keyword">this</span>.metrics.sensor(<span class="hljs-string">"buffer-exhausted-records"</span>).record();        <span class="hljs-keyword">if</span> (<span class="hljs-keyword">this</span>.interceptors != <span class="hljs-keyword">null</span>)            <span class="hljs-keyword">this</span>.interceptors.onSendError(record, tp, e);        <span class="hljs-keyword">throw</span> e;    &#125; <span class="hljs-keyword">catch</span> (KafkaException e) &#123;        <span class="hljs-keyword">this</span>.errors.record();        <span class="hljs-keyword">if</span> (<span class="hljs-keyword">this</span>.interceptors != <span class="hljs-keyword">null</span>)            <span class="hljs-keyword">this</span>.interceptors.onSendError(record, tp, e);        <span class="hljs-keyword">throw</span> e;    &#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;        <span class="hljs-comment">// we notify interceptor about all exceptions, since onSend is called before anything else in this method</span>        <span class="hljs-keyword">if</span> (<span class="hljs-keyword">this</span>.interceptors != <span class="hljs-keyword">null</span>)            <span class="hljs-keyword">this</span>.interceptors.onSendError(record, tp, e);        <span class="hljs-keyword">throw</span> e;    &#125;&#125;</code></pre></p><h3 id="序列化，按配置加载序列化的类"><a href="#序列化，按配置加载序列化的类" class="headerlink" title="序列化，按配置加载序列化的类"></a>序列化，按配置加载序列化的类</h3><pre><code class="hljs java"><span class="hljs-keyword">if</span> (keySerializer == <span class="hljs-keyword">null</span>) &#123;    <span class="hljs-keyword">this</span>.keySerializer = config.getConfiguredInstance(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,            Serializer.class);    <span class="hljs-keyword">this</span>.keySerializer.configure(config.originals(), <span class="hljs-keyword">true</span>);&#125; <span class="hljs-keyword">else</span> &#123;    config.ignore(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);    <span class="hljs-keyword">this</span>.keySerializer = keySerializer;&#125;<span class="hljs-keyword">if</span> (valueSerializer == <span class="hljs-keyword">null</span>) &#123;    <span class="hljs-keyword">this</span>.valueSerializer = config.getConfiguredInstance(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,            Serializer.class);    <span class="hljs-keyword">this</span>.valueSerializer.configure(config.originals(), <span class="hljs-keyword">false</span>);&#125; <span class="hljs-keyword">else</span> &#123;    config.ignore(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);    <span class="hljs-keyword">this</span>.valueSerializer = valueSerializer;&#125;</code></pre><h3 id="计算消息要落到哪个partition"><a href="#计算消息要落到哪个partition" class="headerlink" title="计算消息要落到哪个partition"></a>计算消息要落到哪个partition</h3><pre><code class="hljs java"><span class="hljs-comment">/** * Compute the partition for the given record. * * <span class="hljs-doctag">@param</span> topic The topic name * <span class="hljs-doctag">@param</span> key The key to partition on (or null if no key) * <span class="hljs-doctag">@param</span> keyBytes serialized key to partition on (or null if no key) * <span class="hljs-doctag">@param</span> value The value to partition on or null * <span class="hljs-doctag">@param</span> valueBytes serialized value to partition on or null * <span class="hljs-doctag">@param</span> cluster The current cluster metadata */</span><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">partition</span><span class="hljs-params">(String topic, Object key, <span class="hljs-keyword">byte</span>[] keyBytes, Object value, <span class="hljs-keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;    List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);    <span class="hljs-keyword">int</span> numPartitions = partitions.size();    <span class="hljs-keyword">if</span> (keyBytes == <span class="hljs-keyword">null</span>) &#123;        <span class="hljs-keyword">int</span> nextValue = nextValue(topic);        List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);        <span class="hljs-keyword">if</span> (availablePartitions.size() &gt; <span class="hljs-number">0</span>) &#123;            <span class="hljs-keyword">int</span> part = Utils.toPositive(nextValue) % availablePartitions.size();            <span class="hljs-keyword">return</span> availablePartitions.get(part).partition();        &#125; <span class="hljs-keyword">else</span> &#123;            <span class="hljs-comment">// no partitions are available, give a non-available partition</span>            <span class="hljs-keyword">return</span> Utils.toPositive(nextValue) % numPartitions;        &#125;    &#125; <span class="hljs-keyword">else</span> &#123;        <span class="hljs-comment">// hash the keyBytes to choose a partition</span>        <span class="hljs-keyword">return</span> Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;    &#125;&#125;</code></pre><h3 id="计算消息长度是否合法"><a href="#计算消息长度是否合法" class="headerlink" title="计算消息长度是否合法"></a>计算消息长度是否合法</h3><pre><code class="hljs java"><span class="hljs-keyword">int</span> serializedSize = Records.LOG_OVERHEAD + Record.recordSize(serializedKey, serializedValue);ensureValidRecordSize(serializedSize);</code></pre><h3 id="等待批量发送消息"><a href="#等待批量发送消息" class="headerlink" title="等待批量发送消息"></a>等待批量发送消息</h3><pre><code class="hljs java">tp = <span class="hljs-keyword">new</span> TopicPartition(record.topic(), partition);<span class="hljs-keyword">long</span> timestamp = record.timestamp() == <span class="hljs-keyword">null</span> ? time.milliseconds() : record.timestamp();log.trace(<span class="hljs-string">"Sending record &#123;&#125; with callback &#123;&#125; to topic &#123;&#125; partition &#123;&#125;"</span>, record, callback, record.topic(), partition);<span class="hljs-comment">// producer callback will make sure to call both 'callback' and interceptor callback</span>Callback interceptCallback = <span class="hljs-keyword">this</span>.interceptors == <span class="hljs-keyword">null</span> ? callback : <span class="hljs-keyword">new</span> InterceptorCallback&lt;&gt;(callback, <span class="hljs-keyword">this</span>.interceptors, tp);RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, interceptCallback, remainingWaitMs);<span class="hljs-keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;    log.trace(<span class="hljs-string">"Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch"</span>, record.topic(), partition);    <span class="hljs-keyword">this</span>.sender.wakeup();&#125;<span class="hljs-keyword">return</span> result.future;</code></pre><p>生产者发迭的消息先在客户端缓存到记录收集器RecordAccumulator中，等到一定时机再由发送线程Sender批量地写入Kafka集群。生产者每生产一条消息，就向记录收集器中追加一条消息，追加方法 的返回值表示批记录(RecordBatch)是否满了:如果批记录满了，则开始发送这一批数据。每个分区都有一个双端队列用来缓存客户端的消息，队列的每个元素是一个批记录。一旦分区的队列中有批记录满了，就会被发送线程发送到分区对应的节点;如果批记录没有满，就会继续等待直到收集到足够的消息。</p><p><img src="/2018/07/18/《Kafka技术内幕》-读书笔记2/0069RVTdgy1fu0e6pjje7j31340b6air.jpg" srcset="/img/loading.gif" alt=""></p><p>追加消息时首先要获取分区所属的队列，然后取队列中最后一个批记录，如果队列中不存在批记录或者上一个批记录已经写满，应该创建新的批记录，并且加入队列的尾部。</p><pre><code class="hljs java"><span class="hljs-comment">// We keep track of the number of appending thread to make sure we do not miss batches in</span><span class="hljs-comment">// abortIncompleteBatches().</span>appendsInProgress.incrementAndGet();<span class="hljs-keyword">try</span> &#123;    <span class="hljs-comment">// check if we have an in-progress batch</span>    Deque&lt;RecordBatch&gt; dq = getOrCreateDeque(tp);    <span class="hljs-keyword">synchronized</span> (dq) &#123;        <span class="hljs-keyword">if</span> (closed)            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> IllegalStateException(<span class="hljs-string">"Cannot send after the producer is closed."</span>);        RecordAppendResult appendResult = tryAppend(timestamp, key, value, callback, dq);        <span class="hljs-keyword">if</span> (appendResult != <span class="hljs-keyword">null</span>)            <span class="hljs-keyword">return</span> appendResult;    &#125;    <span class="hljs-comment">// we don't have an in-progress record batch try to allocate a new batch</span>    <span class="hljs-keyword">int</span> size = Math.max(<span class="hljs-keyword">this</span>. , Records.LOG_OVERHEAD + Record.recordSize(key, value));    log.trace(<span class="hljs-string">"Allocating a new &#123;&#125; byte message buffer for topic &#123;&#125; partition &#123;&#125;"</span>, size, tp.topic(), tp.partition());    ByteBuffer buffer = free.allocate(size, maxTimeToBlock);    <span class="hljs-keyword">synchronized</span> (dq) &#123;        <span class="hljs-comment">// Need to check if producer is closed again after grabbing the dequeue lock.</span>        <span class="hljs-keyword">if</span> (closed)            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> IllegalStateException(<span class="hljs-string">"Cannot send after the producer is closed."</span>);        RecordAppendResult appendResult = tryAppend(timestamp, key, value, callback, dq);        <span class="hljs-keyword">if</span> (appendResult != <span class="hljs-keyword">null</span>) &#123;            <span class="hljs-comment">// Somebody else found us a batch, return the one we waited for! Hopefully this doesn't happen often...</span>            free.deallocate(buffer);            <span class="hljs-keyword">return</span> appendResult;        &#125;        MemoryRecordsBuilder recordsBuilder = MemoryRecords.builder(buffer, compression, TimestampType.CREATE_TIME, <span class="hljs-keyword">this</span>.batchSize);        RecordBatch batch = <span class="hljs-keyword">new</span> RecordBatch(tp, recordsBuilder, time.milliseconds());        FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, callback, time.milliseconds()));        dq.addLast(batch);        incomplete.add(batch);        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> RecordAppendResult(future, dq.size() &gt; <span class="hljs-number">1</span> || batch.isFull(), <span class="hljs-keyword">true</span>);    &#125;&#125; <span class="hljs-keyword">finally</span> &#123;    appendsInProgress.decrementAndGet();&#125;<span class="hljs-comment">/** * If `RecordBatch.tryAppend` fails (i.e. the record batch is full), close its memory records to release temporary * resources (like compression streams buffers). */</span><span class="hljs-function"><span class="hljs-keyword">private</span> RecordAppendResult <span class="hljs-title">tryAppend</span><span class="hljs-params">(<span class="hljs-keyword">long</span> timestamp, <span class="hljs-keyword">byte</span>[] key, <span class="hljs-keyword">byte</span>[] value, Callback callback, Deque&lt;RecordBatch&gt; deque)</span> </span>&#123;    RecordBatch last = deque.peekLast();    <span class="hljs-keyword">if</span> (last != <span class="hljs-keyword">null</span>) &#123;        FutureRecordMetadata future = last.tryAppend(timestamp, key, value, callback, time.milliseconds());        <span class="hljs-keyword">if</span> (future == <span class="hljs-keyword">null</span>)            last.close();        <span class="hljs-keyword">else</span>            <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> RecordAppendResult(future, deque.size() &gt; <span class="hljs-number">1</span> || last.isFull(), <span class="hljs-keyword">false</span>);    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;&#125;</code></pre><p><img src="/2018/07/18/《Kafka技术内幕》-读书笔记2/0069RVTdgy1fu0ei7yyvbj30xm0v47mf.jpg" srcset="/img/loading.gif" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>读书笔记</category>
      
      <category>Kafka技术内幕</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>kafka</tag>
      
      <tag>Kafka技术内幕</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《Kafka技术内幕》--读书笔记1</title>
    <link href="/2018/07/15/%E3%80%8AKafka%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/"/>
    <url>/2018/07/15/%E3%80%8AKafka%E6%8A%80%E6%9C%AF%E5%86%85%E5%B9%95%E3%80%8B-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B01/</url>
    
    <content type="html"><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><ul><li>生产者 (producer)应用程序发布事件流到Kafka的一个或多个主题。</li><li>消费者 (consumer)应用程序订阅Kafka的一个或多个主题，并处理事件流。</li><li>连接器 (connector)将Kafka主题和已有数据源进行连接，数据可以互相导人和导出 。</li><li>流处理 (processor)从Kafka主题消费输入流，经过处理后，产生输出流到输出主题。</li></ul><p><img src="/2018/07/15/《Kafka技术内幕》-读书笔记1/006tNc79gy1ftax17fddej30u00liqg7.jpg" srcset="/img/loading.gif" alt=""></p><a id="more"></a><h1 id="分区模型"><a href="#分区模型" class="headerlink" title="分区模型"></a>分区模型</h1><p>Kafka集群向多个消息代理服务器(broker server)组成，发布至UKafka集群的每条消息都有一个类别，用主题(topic)来表示。</p><p>Kafka集群为每个主题维护了分布式的分区(partition)日志文件，物理意义上可以把主题看作分区的日志文件(partitioned log)。 每个分区都是一个有序的、不可变的记录序列，新的消息会不断追加到提交日志(commit log)。分区中的每条消息都会按照时间顺序分配到一个单调递增的顺序编号，叫作偏移盘(offset)，这个偏移量能够唯一地定位当前分区中的每一条消息 。</p><p><img src="/2018/07/15/《Kafka技术内幕》-读书笔记1/006tNc79gy1ftbzeenfd4j311m0hg7gu.jpg" srcset="/img/loading.gif" alt=""></p><p>Kafka以分区作为最小的粒度，将每个分区分配给消费组中不同的而且是唯一的消费者，并确保一个分区只 属于一个消费者，即这个消费者就是这个分区的唯一读取线程 。 </p><h1 id="消费模型"><a href="#消费模型" class="headerlink" title="消费模型"></a>消费模型</h1><p><img src="/2018/07/15/《Kafka技术内幕》-读书笔记1/006tNc79gy1ftbzoyt51tj30wm0do46g.jpg" srcset="/img/loading.gif" alt=""></p><p>Kafka采用拉取模型，由消费者向己记录消费状态，每个消费者五相独立地顺序读取每个分区的消息。<br>生产者发布的所有消息会一直保存在Kafka集群中，不管消息有没有被消费。 用户可以通过设置保留时间来清理过期的数据。</p><h1 id="分布式模型"><a href="#分布式模型" class="headerlink" title="分布式模型"></a>分布式模型</h1><p>Kafka每个主题的多个分区日志分布式地存储在Kafka集群上，同时为了故障容错，每个分区都会以副本的方式复制到多个消息代理节点上。其中一个节点会作为主副本(Leader)，其他节点作为备份副本(Follower，也叫作从副本)。主副本会负责所有的客户端读写操作，备份副本仅仅从主副本同步数据。当主副本 出现故障时，备份副本中的一个副本会被选择为新的主副本 。</p><p>分区是消费者线程模型的最小并行单位。</p><p><img src="/2018/07/15/《Kafka技术内幕》-读书笔记1/006tNc79gy1ftbzzepul7j31cm0dm16c.jpg" srcset="/img/loading.gif" alt=""></p><h1 id="其他设计"><a href="#其他设计" class="headerlink" title="其他设计"></a>其他设计</h1><h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><p>使用“零拷贝技术”(zero-copy)只需将磁盘文件的数据复制到页面缓存中一次，然后将数据从页面缓存直接发送到网络中(发送给不同的使用者时，都可以重复使用同一个页面缓存)，避免了重复的复制操作。</p><p><img src="/2018/07/15/《Kafka技术内幕》-读书笔记1/006tNc79gy1ftc0gx0ft5j31b00o0qp3.jpg" srcset="/img/loading.gif" alt=""></p><h2 id="生产者与消费者"><a href="#生产者与消费者" class="headerlink" title="生产者与消费者"></a>生产者与消费者</h2><p>Kafka的生产者将消息直接发送给分区主副本所在的消息代理节点，并不需要经过任何的中间路由层。为了做到这一点，所有消息代理节点都会保存一份相同的元数据，这份元数据记录了每个主题分区对应的主副本节点。生产者客户端在发送消息之前，会向任意一个代理节点请求元数据，井确定每条消息对应的目标节点然后把消息直接发送给对应的目标节点 。</p><p>生产者采用批量发送消息集的方式解决了网络请求过多的问题。生产者会尝试在内存中收集足够数据，并在一个请求中一次性发送一批数据。</p><p>Kafka采用了基于拉取模型的消费状态处理，它将主题分成多个有序的分区，任何时刻每个分区都只被一个消费者使用。并且，消费者会记录每个分区的消费进度(即偏移量)。Kafka的消费者会定时地将分区的消费进度保存成检<br>查点文件，表示“这个位置之前的消息都已经被消费过了”</p><p>和生产者采用批量发送消息类似，消费者拉取消息也可以一次拉取一批消息。消费者客户端拉取消息，然后处理这一批消息，这个过程一般套在一个死循环里，表示消费者永远处于消费消息的状态</p><h2 id="副本和容错"><a href="#副本和容错" class="headerlink" title="副本和容错"></a>副本和容错</h2><p>备份副本始终尽量保持与主副本的数据同步。备份副本的日志文件和主副本的日志总是相同的，它们都有相同的偏移量和相同顺序的消息。备份副本从主副本消费消息的方式和普通的消费者一样，只不过备份副本会将消息运用到自己的本地日志文件(备份副本和主副本都在服务端，它们都会将收到的分区数据持久化成日志文件)。 </p><p>kafka对节点的存活定义有两个条件:</p><ul><li>节点必须和ZK保持会话; </li><li>如果这个节点是某个分区的备份副本，它必须对分区主副本的写操作进行复制，并且复制的进度不能落后太多。</li></ul><p>如果一个备份副本挂掉、没有响应或者落后太多，主副本就会将其从同步副本集合中移除。反之，如果备份副本重新赶上主副本，它就会加入到主副本的 同步集合中。</p><p>在Kafka中，一条消息只有被ISR集合的所有副本都运用到本地的日志文件，才会认为消息被成功提交了。任何时刻，只要ISR至少有一个副本是存活的， Kafka就可以保证“一条消息一旦被提交，就不会丢失”。只有已经提交的消息才能被消费者消费，因此消费者不用担心会看到因为主副本失败而丢失的消息。</p>]]></content>
    
    
    <categories>
      
      <category>读书笔记</category>
      
      <category>Kafka技术内幕</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
      <tag>kafka</tag>
      
      <tag>Kafka技术内幕</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2018/07/13/hello-world/"/>
    <url>/2018/07/13/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="hljs bash">$ hexo new <span class="hljs-string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="hljs bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="hljs bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="hljs bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
